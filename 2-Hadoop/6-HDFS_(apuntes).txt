APUNTES HDFS
==============

Analizar archivos o directorios
-------------------------------
                 ____________________________________________________________________
                |                                                                    |                                           
                |       drwxr-xr-x 3 alfonso alfonso 4096 Jan  8 13:55 airflow       |
                |____________________________________________________________________|

DESCRIPCION
 
  1    2     3     4
| d | rwx | r-x | r-x |  ==> Se divide en 4 partes

Parte 1 ==>  Si es una d : es un directorio
             Si es un - : es un archivo (imagen, archivo cualquiera) 

Parte 2 ==>  Los archivos pueden ser Readable(r), Writable(w) o Executable(x).
             Los tres primeros caracteres se refieren al owner del archivo y nos est√°n 
             diciendo que el owner puede leer escribir y tambi√©n ejecutar el archivo.

Parte 3 ==>  Los segundos tres caracteres se refieren al "grupo" al que est√° asignada 
             esta carpeta, a los usuarios que pertenecen a este grupo. Y nos est√°n 
             diciendo que esta carpeta es del grupo "Alfonso", pueden leer esta carpeta (r). 
             No pueden escribir esta carpeta. De hecho, no hay una (w) aqu√≠, s√≥lo hay una 
             l√≠nea. Y pueden ejecutar el archivo (x).       

Parte 4 ==>  Y el tercer grupo de tres caracteres nos dicen que se refieren a todos los 
             dem√°s. As√≠ que todos los dem√°s no era el propietario y tampoco es usuario del 
             grupo "Alfonso". Por lo tanto, todos los dem√°s pueden leer este archivo (r). 
             No pueden escribir en este archivo, pero pueden ejecutar (x).   

3 alfonso alfonso 4096 Jan  8 13:55 airflow  

3       ==>  Es el n√∫mero de archivos que se encuentran en este directorio.

alfonso ==>  Este es el owner. Significa que esta carpeta pertenece a 'Alfonso'.   

alfonso ==>  Es el grupo al que est√° asignada esta carpeta de aplicaci√≥n. Cada archivo o 
             directorio se asigna a un Grupo que contiene uno o m√°s usuarios.

4096    ==>  Nos indica el peso del directorio en este caso.   

Jan  8 13:55  ==>  Fecha de modificaci√≥n del recurso

airflow ==>  Nombre del recurso

             
---------------------------------------------------------------------------------------------------------------- 

Clase 2 --> 00:40:00
---------------------

Nos explica que los directorios que se visualizan en MobaXterm, si buscamos 
los directorios de la raiz (root), seran directorios que pertenecen al Disco 
duro del servidor GETWAY. Sin embargo, al ingresar al sitio de 'HUE' y buscar 
los directorios de la raiz (root) podemos visualizar directorios distintos, 
ya que, estos pertenecen a los discos duros de los servidores SLAVE, es decir,
al 'Gran disco duro virtual'.

                     
Buscar üîé: /        _______________________________________
                    |            |            |            |       ______\  Recordar que son varios servidores SLAVE, 
- Directorio A      |   GETWAY   |   MASTER   |    SLAVE   |      |      /  y gracias a Hadoop lo podemos ver como un  
- Directorio B      |____________|____________|____________|      |         'gran unico servidor', un 'gran unico
- Directorio C      |            |            |            |      |          computador', un 'gran disco duro virtual'.
- Directorio D      |  _______   |            |  _______   |      |     
|              |    | |     ‚óã |  |            | |     ‚óã |  |      |         Desde el sitio de 'HUE':
|______________|    | |       |  |            | |       |---------'         Buscar üîé: /
       |            | |_______|  |            | |_______|  |                
       |            |     ÀÑ      |            |            |                - Directorio E
       |__________________|      |            |            |                - Directorio F
                    |            |            |            |                - Directorio G
                    |____________|____________|____________|                - Directorio H
Esto es lo que vemos
en MobaXterm al                                                              Vemos directorios distintos a los que estamos   
momento de conectarnos.                                                      visualizando desde MobaXterm. Esto porque, los
Estos directorios                                                            directorios pertenecen al Disco duro de los servidores               
pertenecen al Disco                                                          Esclavos.
duro, del servidor
GETWAY.

---------------------------------------------------------------------------------------------------------------- 

Clase 2 =====> COMANDOS PARA LISTAR ARCHIVOS
-------

hdfs dfs -ls /	  :   Lista todos los archivos y directorios para la ruta 'root' o 'raiz'. HDFS es un sistema de 
                      archivos, por lo tanto tiene una carpeta ra√≠z (/) donde se encuentran todas sus otras carpetas

hdfs dfs -ls -h / :   Lista los archivos con su tama√±o en formato legible. Se especifican las unidades de Kilobytes (K), 
                      Megabytes (M) y Gigabytes (G)

hdfs dfs -ls -R / :   Lista todos los archivos y directorios recursivamente (con subdirectorios).

hdfs dfs -ls /file* :   Lista todos los archivos que cumplen el patr√≥n (archivos que comienzan con ‚Äòfile‚Äô)

---------------------------------------------------------------------------------------------------------------- 

Clase 2 =====> COMANDOS PARA LEER Y ESCRIBIR ARCHIVOS
-------

hdfs dfs -text /hadoop/app.log	:  Imprime el archivo en modo texto por la terminal

hdfs dfs -cat /hadoop/app.log	:  Muestra el contenido del archivo en la salida est√°ndar. Visualizamos TODO EL CONTENIDO 
                                   del archivo especificado por consola.

hdfs dfs -tail /hadoop/archivo  :  Muestra los √∫ltimos registros de un archivoNos va a permitir solo visualizar la 
                                   "cola" del archivo, es decir, solo visualizar sus √∫ltimos registros.

hdfs dfs -appendToFile /home/file1 /file2   : A√±ade el contenido del archivo local 'file1' al archivo en hdfs 'file2'

---------------------------------------------------------------------------------------------------------------- 

Clase 2 =====> COMANDOS PARA CARGAR Y DESCARGAR ARCHIVOS
-------

hdfs dfs -put /home/file1  /hadoop    :  Copia el archivo 'file1' del sistema de archivos local (Getway) a hdfs

hdfs dfs -put -f /home/file1 /hadoop  :  Copia el archivo 'file1' del sistema de archivos local a hdfs y lo 
                                         sobreescribe en el caso de que ya exista

hdfs dfs -put -l /home/file1 /hadoop  :  Copia el archivo 'file1' del sistema de archivos local a hdfs. Fuerza 
                                         replicaci√≥n 1 y permite al DataNode persistir los datos de forma perezosa.

hdfs dfs -put -p /home/file1 /hadoop  : Copia el archivo 'file1' del sistema de archivos local a hdfs. Mantiene los 
                                        tiempos de acceso, de modificaci√≥n y propietario original.

hdfs dfs -get /hadoopfile1 /home/     :   Copia el archivo 'file1' de hdfs al sistema de archivos local   

hdfs dfs -moveFromLocal /home/file1 /hadoop   :  Copia el archivo ‚Äòfile1‚Äô del sistema de archivos local a hdfs y 
                                                 luego lo borra del sist. archivos local.

---------------------------------------------------------------------------------------------------------------- 

Clase 2 =====> COMANDOS PARA GESTION DE ARCHIVOS
-------

hdfs dfs -cp /hadoop/file1 /hadoop1    :  Copia el archivo al directorio destino en hdfs

hdfs dfs -cp -p /hadoop/file1 /hadoop1 : Copia el archivo al directorio destino en hdfs conservando tiempos 
                                         de acceso y de modificaci√≥n, propietario y modo

hdfs dfs -rm -f /hadoop/file1          :  Elimina el archivo 'file1' de hdfs y lo env√≠a a la papelera.

hdfs dfs -rm -r -f /hadoop             :  Eliminar un directorio. Tambi√©n podemos utilizarlo para eliminar 
                                          archivos. 

hdfs dfs -touchz /hadoop/archivo_vacio :  Crea un archivo en hdfs con tama√±o 0. A pesar que el archivo es un 
                                          archivo vacio se generan 3 copias.

hdfs dfs -mkdir /hadoop/directorio_nuevo   :  Crea un directorio en hdfs. Nos permite crear un nuevo directorio, 
                                              siempre y cuando la ruta previa a este nuevo directorio exista.

hdfs dfs -mkdir -p /hadoop/directorio_nuevo1/directorio_nuevo2/.../archivo   : Nos garantiza que creara toda la 
                                                                               estructura intermedia de directorios, 
                                                                               no solamente el ultimo directorio.

hdfs dfs -mv /hadoop/directorioA/archivo  /hadoop/directorioB   :  Mover un archivo entre directorios

hdfs dfs -chown <nuevo_usuario>:<nuevo_grupo> /<ruta_directorio_o_archivo> :  Cambiar el owner de un directorio o archivo.
                                                                              Para utilizar este comando, debemos estar 
                                                                              logeados con el super usuario ‚Äòhdfs‚Äô.

hdfs dfs -chown -R <nuevo_usuario>:<nuevo_grupo> /<ruta_directorio_o_archivo> :  Cambiar el owner de un directorio o 
                                                                                 archivo de manera recursiva. Esto nos 
                                                                                 permite cambiar todos los archivos y 
                                                                                 subdirectorios dentro del directorio 
                                                                                 especificado.

---------------------------------------------------------------------------------------------------------------- 

Clase 2 --> 00:48:30
--------------------

¬øComo navegamos por los archivos del gran disco duro virtual (nodos SLAVE)
utilizando MobaXterm?

Utilizando el prefijo 'hdfs dfs' ===> Por ejemplo, para listar los archivos 
utilizamos:
                      ______________________________
                     |                              |    
                     |      hdfs dfs -ls /ruta      |
                     |      hdfs dfs -ls -h /ruta   |
                     |______________________________|

---------------------------------------------------------------------------------------------------------------- 

Clase 2 --> 00:51:39
--------------------

Solo los archivos tienen copias, NO LOS DIRECTORIOS. Esto porque un 'Directorio' es METADATA,
no ocupa espacio en Disco duro, asi que solamente se hacen replicas de los archivos.

---------------------------------------------------------------------------------------------------------------- 

Clase 2 --> 01:14:54
--------------------

Para cargar un archivo que se encuentre en el 'Disco duro Getway' (Disco local) al 'Disco duro Slave' 
(HDFS), debemos utilizar el siguiente comando:

                      ________________________________________________
                     |                                                |    
                     |      hdfs dfs -put /home/archivo  /hadoop      |
                     |________________________________________________|

Cargamos el archivo ‚Äúarchivo‚Äù que se encontraba en el disco duro Getway, mas espec√≠ficamente en la 
ruta /home/archivo, en la ruta del disco duro Slave, mas espec√≠ficamente en el directorio /hadoop. 

---------------------------------------------------------------------------------------------------------------- 

Clase 2 --> 01:22:20
        --> 01:27:40
--------------------

Otro punto importante es la PAPELERA DE RECICLAJE DE LOS SISTEMAS DE ARCHIVOS DISTRIBUIDOS, ya sea, en 
HDFS, DBFS, S3 o con cualquier sistema on-premise o en la nube, al momento de que se elimine algo, eso 
NO SE ELIMINA DE MANERA PERMANENTE, sino que se va a una especie de papelera de reciclaje. 

Para eliminar y enviar un archivo a Papelera de reciclaje utilizamos el siguiente comando:

                      ___________________________________________
                     |                                           |    
                     |      hdfs dfs -rm -f /hadoop/archivo      |
                     |___________________________________________|

Luego el archivo ser√° enviado a la ruta de la Papelera de reciclaje:
                      _____________________________________________________________________
                     |                                                                     |    
                     |      hdfs://........./user/hdfs/.Thrash/Current/hadoop/archivo      |
                     |_____________________________________________________________________|


==> "/user" : es la ruta con el usuario con el que estamos logeados. Esto quiere decir que al estar 
              logeados con nuestro usuario, vamos a tener NUESTRA PROPIA Papelera de reciclaje.

==> "/.Thrash" : Los archivos y directorios ocultos sobre Linux siempre comienzan con un '.' (un punto).
                 En HDFS tambien es lo mismo, pero va a depender de la configuracion del Cluster. En la
                 gran mayoria de casos esta desactivado, es decir, que al momento de crear archivos y 
                 directorios ocultos los vamos a poder ver.

---------------------------------------------------------------------------------------------------------------- 

Clase 2 --> 01:35:02
--------------------

Eliminar el CONTENIDO de la Papelera de reciclaje con el siguiente comando:
                      ___________________________________________________
                     |                                                   |    
                     |      hdfs dfs -rm -r -f /user/hdfs/.Thrash/*      |
                     |___________________________________________________|

Para realizar un BORRADO PERMANENTE sin pasar por Papelera de reciclaje lo realizamos con el siguiente
comando:
                      ________________________________________________________
                     |                                                        |    
                     |      hdfs dfs -rm -r -f -skipTrash /hadoop/archivo     |
                     |________________________________________________________|                     

---------------------------------------------------------------------------------------------------------------- 
   
Clase 3 --> 00:29:00  =====>  VERIFICACION DE INTEGRIDAD DE LOS DATOS  
--------------------                   


Al momento de subir los archivos tenemos que SIEMPRE hacer una VERIFICACION DE INTEGRIDAD 
DE LOS DATOS. ¬øComo hacemos esto? Utilizando la tecnica de "CHECKSUM". ¬øEn que consiste esto?
Nosotros le aplicaremos esta funcion a nuestro archivo que se encuentra en el 'nodo Getway' y 
este nos devolvera un valor numerico. Al archivo que ya lo subimos y esta cargado en HDFS
(Cluster virtual) le aplicaremos la misma funcion y tambien nos devolvera un valor numerico.
Si ambos valores son iguales EXISTE INTEGRIDAD EN LOS DATOS. 

Si por ejemplo, subimos un archivo a HDFS (al Cluster virtual):
                      _________________________________________________
                     |                                                 |    
                     |       hdfs dfs -put /home/archivo  /hadoop      |
                     |_________________________________________________|

Inmediatamente le aplicamos la funcion 'checksum' al archivo:
                      _________________________________________________
                     |                                                 |    
                     |                cksum /home/archivo              |
                     |_________________________________________________|

Y esto nos va a retornar un valor numerico:
                      _________________________________________________
                     |                                                 |    
                     |                    229400302                    |
                     |_________________________________________________|

Luego, de haber cargado el archivo a HDFS y aplicar la funcion CHECKSUM al archivo en el Getway,
aplicamos ahora la funcion al archivo en el HDFS:
                      _________________________________________________
                     |                                                 |    
                     |       hdfs dfs -cat /hadoop/archivo | cksum     |
                     |_________________________________________________|

Y esto nos va a retornar un valor numerico:
                      _________________________________________________
                     |                                                 |    
                     |                    229400302                    |
                     |_________________________________________________|

Al ser ambos numeros iguales EXISTE INTEGRIDAD DE DATOS.                     

---------------------------------------------------------------------------------------------------------------- 

Clase 3 --> 00:29:30  =====>  LISTADO DE PESOS RECURSIVOS  
--------------------   
                      _________________________________________________
                     |                                                 |    
                     |         hdfs dfs -du -s -h '/hadoop/*'          |
                     |_________________________________________________|

Nos devuelve dos valores de tama√±o y la ruta del recurso de la siguiente forma:
                      _________________________________________________
                     |                                                 |    
                     |          28.4K  85.3K   /hadoop/hive            |
                     |_________________________________________________|

Donde el primer tama√±o es el PESO REAL y el segundo es aplicando la TRIPLE REPLICACION que realiza Hadoop, que
corresponde al PESO FISICO EN DISCO DURO, porque se esta ocupando el triple de espacio.

---------------------------------------------------------------------------------------------------------------- 

Clase 3 --> 00:31:00  =====>  MODIFICAR EL NUMERO DE REPLICAS 
--------------------  

Podemos aumentar o disminuir el n√∫mero de r√©plicas. El numero '5' corresponde al numero de replicas. Podria
ser cualquier numero que necesitemos.
                      _________________________________________________
                     |                                                 |    
                     |         hdfs dfs -setrep -w 5 -R /hadoop        |
                     |_________________________________________________|

---------------------------------------------------------------------------------------------------------------- 

Clase 3 --> 00:32:50  =====>  MODIFICAR EL TAMA√ëO DE BLOQUE
--------------------          EXPLICACION DEL PORQUE NO SE RECOMIENDA CARGAR ARCHIVOS MUY PEQUE√ëOS Y SU
                              RELACION CON EL TAMA√ëO DE BLOQUE

Por defecto el tama√±o de bloque de un archivo almacenado sobre HDFS es de 128MB. Si estamos guardando archivos 
muy peque√±os (p.e., de 10 MB) no tiene sentido guardarlo en un tama√±o de bloque tan grande. Para esto al momento 
de subir el archivo podemos guardarlo indicando el tama√±o de bloque. El tama√±o de bloque es indicado en bytes. 
En el ejemplo el tama√±o de bloque es colocado a 1MB.
                      ________________________________________________________________________________
                     |                                                                                |    
                     |         hdfs dfs -D dfs.blocksize=102400 -put /home/file.txt /hadoop        |
                     |________________________________________________________________________________|

---------------------------------------------------------------------------------------------------------------- 